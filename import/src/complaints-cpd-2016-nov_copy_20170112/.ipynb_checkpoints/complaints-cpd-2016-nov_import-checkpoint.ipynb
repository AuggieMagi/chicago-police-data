{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import io\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that help with the magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can be used to remove columns that are all nulls so you don't have to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_dropper(df):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    info_values = [x[0] for x in info_values if x[1].startswith('0 non-null')]\n",
    "    df = df.drop(info_values,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates metadata as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metadata_dataset(df,file):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    metadata_df = pd.DataFrame(info_values)\n",
    "    metadata_df[\"File\"] = file\n",
    "    metadata_df.columns = [\"Column_Name\",\"Column_Info\",\"Original_Dataset\"]\n",
    "    ## Column Info Split\n",
    "    metadata_df['Non_Null_Count'], metadata_df['Object_Type'] = metadata_df['Column_Info'].str.split(' ', 1).str\n",
    "    metadata_df[\"Object_Type\"] = metadata_df[\"Object_Type\"].str.replace(\"non-null \",\"\")\n",
    "    ## unique counts for each variable\n",
    "    uniques_df = df.apply(lambda x: len(x.unique())).reset_index()\n",
    "    uniques_df.columns = [\"Column_Name\",\"Unique_Count\"]\n",
    "    metadata_df[\"Unique_Count\"] = uniques_df[\"Unique_Count\"]\n",
    "    metadata_df = metadata_df[[\"Original_Dataset\",\"Column_Name\",\"Non_Null_Count\",\"Unique_Count\",\"Object_Type\"]]\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts single column named City_State_Zip into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def city_state_zip_splitter(df):\n",
    "    new_states_list=[]\n",
    "    for value in df[\"City_State_Zip\"]:\n",
    "        ## check if it contains a number (zipcode)\n",
    "        if hasNumbers(value):\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 3 values\n",
    "            while len(split_state)>3:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        else:\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 2 values\n",
    "            while len(split_state)>2:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        new_states_list.append(split_state)\n",
    "    city_state_zip =  pd.DataFrame(new_states_list)\n",
    "    city_state_zip.columns = [\"City\",\"State\",\"Zip\"]\n",
    "    return city_state_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishes General Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/thudson/Documents/Github/chicago-police-data/import\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = path + '/input/complaints-cpd-2016-nov_copy_20170112/'\n",
    "out_path =path + '/output/complaints-cpd-2016-nov_copy_20170112/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_code = pd.read_csv(path+'/doc/Location_Code_Dictionary.csv')\n",
    "location_code.dropna(how='all', inplace=True)\n",
    "location_code['Location_Code']=location_code['Location_Code'].astype(int).astype(str)\n",
    "\n",
    "def padding(value):\n",
    "    if len(value)<2:\n",
    "        return \"0\"+value\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "location_code['Location_Code'] = location_code['Location_Code'].apply(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nov 2016 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p046957 - report 1.1 - all complaints in time frame.xls',\n",
       " 'p046957 - report 1.2 - all complaints in time frame.xls',\n",
       " 'p046957 - report 1.3 - all complaints in time frame.xls',\n",
       " 'p046957 - report 1.4 - all complaints in time frame.xls',\n",
       " 'p046957 - report 1.5 - all complaints in time frame.xls',\n",
       " 'p046957 - report 1.6 - all complaints in time frame.xls']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_nov_2016_report = in_path\n",
    "out_path_nov_2016_report = out_path\n",
    "\n",
    "files = os.listdir(in_path_nov_2016_report)\n",
    "files = [file for file in files if '.xls' in file and '1.' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_files = [file.replace(\" \",\"_\").replace(\".xls\",\"\") for file in files]\n",
    "saving_files = saving_files[0].replace('.1',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p046957 - report 1.1 - all complaints in time frame.xls\n",
      "p046957 - report 1.2 - all complaints in time frame.xls\n",
      "p046957 - report 1.3 - all complaints in time frame.xls\n",
      "p046957 - report 1.4 - all complaints in time frame.xls\n",
      "p046957 - report 1.5 - all complaints in time frame.xls\n",
      "p046957 - report 1.6 - all complaints in time frame.xls\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in files: \n",
    "    print(file)\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing, +1 because of header in first df\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    ## remove end of record rows and page number row\n",
    "    df = df.dropna(subset=[\"Number:\",\"Beat:\",\"Location Code:\",\"Address of Incident:\",\"Unnamed: 6\"\n",
    "                     ,\"Incident Date & Time\",\"Complaint Date\",\"Closed Date\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## Need to move Investigator Name to Col 12\n",
    "    df['Number:'].fillna(method='ffill', inplace=True)\n",
    "    df['Number:'] = df['Number:'].astype(int)\n",
    "\n",
    "    ## Investigator Rows have all others as null\n",
    "    df1 = df[\n",
    "       df[\"Incident Date & Time\"].isnull() & \n",
    "       df[\"Complaint Date\"].isnull() &\n",
    "       df[\"Closed Date\"].isnull()].loc[:,(\"Number:\",\"Location Code:\",\n",
    "                                          \"Address of Incident:\",\"Unnamed: 4\",\n",
    "                                          \"Unnamed: 5\",\"Unnamed: 6\")]\n",
    "\n",
    "    df1.columns=[\"Number:\",\"Investigator:\",\"Assignment\",\"Rank\",\"Star\",\"Appt_Date\"]\n",
    "\n",
    "    ## Merge Back Rows \n",
    "    df2 = df.merge(df1,how=\"left\",on=\"Number:\")\n",
    "\n",
    "    ## Drop Original all null Investigator Rows\n",
    "    df2 = df2.dropna(subset=[\"Incident Date & Time\",\n",
    "                     \"Complaint Date\",\"Closed Date\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## Replace ---- with empty strings\n",
    "    df2 = df2.replace('----', \"\").replace('-----', \"\")\n",
    "    ## Drop all null columns\n",
    "    df2 = null_dropper(df2)\n",
    "\n",
    "    ## Covert Address Columns into single column\n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].astype(str)\n",
    "    df2[\"Unnamed: 4\"] = df2['Unnamed: 4'].astype(str)\n",
    "    df2[\"Unnamed: 5\"] = df2['Unnamed: 5'].astype(str)\n",
    "    df2[\"Unnamed: 6\"] = df2['Unnamed: 6'].astype(str)\n",
    "\n",
    "    df2[\"Address of Incident:\"] = df2[[\"Address of Incident:\",\"Unnamed: 4\", \"Unnamed: 5\"]].apply(lambda x: ' '.join(x), axis=1)\n",
    "    \n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].str.replace(\"nan\",\"\")\n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].str.strip()\n",
    "    \n",
    "    df2 = df2[[\"Number:\",\"Beat:\",\"Location Code:\",\"Address of Incident:\",\"Unnamed: 6\",\n",
    "               \"Incident Date & Time\",\"Complaint Date\",\"Closed Date\",\"Investigator:\",\n",
    "              \"Assignment\",\"Rank\",\"Star\",\"Appt_Date\"]]\n",
    "\n",
    "    df2.columns = [\"CRID\",\"Beat\",\"Location_Code\",\"Address_of_Incident\",\n",
    "                      \"City_State_Zip\",\"Incident_Date\",\"Complaint_Date\", \n",
    "                      \"Closed_Date\",\"Investigator_Full_Name\",\n",
    "                  \"Investigator_Assignment\",\"Investigator_Rank\",\n",
    "                   \"Investigator_Star\",\"Investigator_Appt_Date\"]\n",
    "\n",
    "    ## Splitting City State Zip into three columns\n",
    "    city_state_zip = city_state_zip_splitter(df2)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    df2 = df2.merge(city_state_zip,how='left',right_index=True,left_index=True)\n",
    "    ## Appending Location Type\n",
    "    df2 = df2.merge(location_code,how='left',on='Location_Code')\n",
    "    \n",
    "    df2 = df2 [[\"CRID\",\"Beat\",\"Location_Code\",\"Location_Value\",\"Address_of_Incident\",\n",
    "                      \"City\",\"State\",\"Zip\",\"Incident_Date\",\"Complaint_Date\", \n",
    "                      \"Closed_Date\",\"Investigator_Full_Name\",\n",
    "                  \"Investigator_Assignment\",\"Investigator_Rank\",\n",
    "                   \"Investigator_Star\",\"Investigator_Appt_Date\"]]\n",
    "    \n",
    "    ## Adding File Metadata\n",
    "    df2[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''  \n",
    "    ## Appending to Final File + Metadata\n",
    "    final_df = final_df.append(df2)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df2,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Location_Code</th>\n",
       "      <th>Location_Value</th>\n",
       "      <th>Address_of_Incident</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Incident_Date</th>\n",
       "      <th>Complaint_Date</th>\n",
       "      <th>Closed_Date</th>\n",
       "      <th>Investigator_Full_Name</th>\n",
       "      <th>Investigator_Assignment</th>\n",
       "      <th>Investigator_Rank</th>\n",
       "      <th>Investigator_Star</th>\n",
       "      <th>Investigator_Appt_Date</th>\n",
       "      <th>FOIA_Request_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258996</td>\n",
       "      <td>1524</td>\n",
       "      <td>04</td>\n",
       "      <td>Police Building</td>\n",
       "      <td>5327 W CHICAGO</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>2000-01-01 01:20:00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2001-01-26</td>\n",
       "      <td>SCHWIEGER, STEVEN</td>\n",
       "      <td>013</td>\n",
       "      <td>LIEUTENANT OF POLICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-06-16 00:00:00</td>\n",
       "      <td>FOIA P046957\\nReport 1.1\\nAll Complaints in CR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258997</td>\n",
       "      <td>1115</td>\n",
       "      <td>17</td>\n",
       "      <td>Public Way - Other</td>\n",
       "      <td>4316 W JACKSON</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>2000-01-01 01:30:00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-10-14</td>\n",
       "      <td>MULLIGAN JR, MICHAEL</td>\n",
       "      <td>008</td>\n",
       "      <td>SERGEANT OF POLICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-12-14 00:00:00</td>\n",
       "      <td>FOIA P046957\\nReport 1.1\\nAll Complaints in CR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258998</td>\n",
       "      <td>1834</td>\n",
       "      <td>17</td>\n",
       "      <td>Public Way - Other</td>\n",
       "      <td>500 W ILLINOIS</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>2000-01-01 00:28:00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2001-01-18</td>\n",
       "      <td>MC MAHON, MAUREEN</td>\n",
       "      <td>608</td>\n",
       "      <td>LIEUTENANT OF POLICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-07-01 00:00:00</td>\n",
       "      <td>FOIA P046957\\nReport 1.1\\nAll Complaints in CR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258999</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Public Way - Other</td>\n",
       "      <td></td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>2000-01-01 03:30:00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-03-23</td>\n",
       "      <td>DEAN, BRUCE</td>\n",
       "      <td>113</td>\n",
       "      <td>SUPERVISING INV IPRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-09-16 00:00:00</td>\n",
       "      <td>FOIA P046957\\nReport 1.1\\nAll Complaints in CR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259000</td>\n",
       "      <td>1524</td>\n",
       "      <td>04</td>\n",
       "      <td>Police Building</td>\n",
       "      <td>5327 W CHICAGO AVE</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>2000-01-01 05:00:00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2001-01-17</td>\n",
       "      <td>LABERN, LINDA</td>\n",
       "      <td>020</td>\n",
       "      <td>SERGEANT OF POLICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973-07-16 00:00:00</td>\n",
       "      <td>FOIA P046957\\nReport 1.1\\nAll Complaints in CR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRID  Beat Location_Code      Location_Value Address_of_Incident  \\\n",
       "0  258996  1524            04     Police Building      5327 W CHICAGO   \n",
       "1  258997  1115            17  Public Way - Other      4316 W JACKSON   \n",
       "2  258998  1834            17  Public Way - Other      500 W ILLINOIS   \n",
       "3  258999     0            17  Public Way - Other                       \n",
       "4  259000  1524            04     Police Building  5327 W CHICAGO AVE   \n",
       "\n",
       "      City State   Zip       Incident_Date Complaint_Date Closed_Date  \\\n",
       "0  CHICAGO    IL  None 2000-01-01 01:20:00     2000-01-01  2001-01-26   \n",
       "1  CHICAGO    IL  None 2000-01-01 01:30:00     2000-01-01  2000-10-14   \n",
       "2  CHICAGO    IL  None 2000-01-01 00:28:00     2000-01-01  2001-01-18   \n",
       "3  CHICAGO    IL  None 2000-01-01 03:30:00     2000-01-01  2000-03-23   \n",
       "4  CHICAGO    IL  None 2000-01-01 05:00:00     2000-01-01  2001-01-17   \n",
       "\n",
       "  Investigator_Full_Name Investigator_Assignment     Investigator_Rank  \\\n",
       "0      SCHWIEGER, STEVEN                     013  LIEUTENANT OF POLICE   \n",
       "1   MULLIGAN JR, MICHAEL                     008    SERGEANT OF POLICE   \n",
       "2      MC MAHON, MAUREEN                     608  LIEUTENANT OF POLICE   \n",
       "3            DEAN, BRUCE                     113  SUPERVISING INV IPRA   \n",
       "4          LABERN, LINDA                     020    SERGEANT OF POLICE   \n",
       "\n",
       "   Investigator_Star Investigator_Appt_Date  \\\n",
       "0                NaN    1986-06-16 00:00:00   \n",
       "1                NaN    1970-12-14 00:00:00   \n",
       "2                NaN    1985-07-01 00:00:00   \n",
       "3                NaN    1995-09-16 00:00:00   \n",
       "4                NaN    1973-07-16 00:00:00   \n",
       "\n",
       "                                 FOIA_Request_Number  \n",
       "0  FOIA P046957\\nReport 1.1\\nAll Complaints in CR...  \n",
       "1  FOIA P046957\\nReport 1.1\\nAll Complaints in CR...  \n",
       "2  FOIA P046957\\nReport 1.1\\nAll Complaints in CR...  \n",
       "3  FOIA P046957\\nReport 1.1\\nAll Complaints in CR...  \n",
       "4  FOIA P046957\\nReport 1.1\\nAll Complaints in CR...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_nov_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_nov_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_nov_2016_report+saving_files+\"_metadata.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p046957 - report 2.1 - identified accused.xls',\n",
       " 'p046957 - report 2.2 - identified accused.xls',\n",
       " 'p046957 - report 2.3 - identified accused.xls',\n",
       " 'p046957 - report 2.4 - identified accused.xls',\n",
       " 'p046957 - report 2.5 - identified accused.xls']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_nov_2016_report = in_path\n",
    "out_path_nov_2016_report = out_path\n",
    "\n",
    "files = os.listdir(in_path_nov_2016_report)\n",
    "files = [file for file in files if '.xls' in file and '2.' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_files = [file.replace(\" \",\"_\").replace(\".xls\",\"\") for file in files]\n",
    "saving_files = saving_files[0].replace('.1',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "    # +1 because of python indexing,\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    ## Remove leading and trailing whitespace from columns \n",
    "    df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "    ## Need to fill in Number\n",
    "    df['Number:'].fillna(method='ffill', inplace=True)\n",
    "    df['Number:'] = df['Number:'].astype(int)\n",
    "\n",
    "    ## Drops end of record \n",
    "    df = df.dropna(subset=[\"Accused:\",\"Gender:\",\"Date of Appt:\",\"Star:\"],how=\"all\",axis=0)\n",
    "    \n",
    "    ## drops the significant number of columns that are all nulls\n",
    "    df = null_dropper(df)\n",
    "    ##print(df.head())\n",
    "    df.columns = [\"CRID\",\"Accused\",\"Accused_Birth_Year\",\"Accused_Gender\",\"Accused_Race_Code\",\"Date_of_Appt\",\"Current_Unit\",\"Current_Rank\",\n",
    "                  \"Star\",\"Complaint_Category\",\"Orig_Finding\",\"Orig_Recommended_Discipline\",\"Final_Finding\",\n",
    "                 \"Final_Recommended_Discipline\"]\n",
    "\n",
    "    ## Excel reads NA as null for Orig and Final Finding, this returns it to NA status when discipline is not null\n",
    "    df[\"Orig_Finding\"] = df['Orig_Finding'].astype(str)\n",
    "    df[\"Orig_Finding\"] =np.where((df[\"Orig_Finding\"]=='nan') & (~df[\"Orig_Recommended_Discipline\"].isnull()),\n",
    "                                 \"NA\",\n",
    "                                 df[\"Orig_Finding\"])\n",
    "\n",
    "    df[\"Final_Finding\"] = df['Final_Finding'].astype(str)\n",
    "    df[\"Final_Finding\"] = np.where((df[\"Final_Finding\"]=='nan') & (~df[\"Final_Recommended_Discipline\"].isnull()),\n",
    "                                 \"NA\",\n",
    "                                 df[\"Final_Finding\"])\n",
    "    \n",
    "    ## replace the actual nulls with blanks\n",
    "    df[\"Orig_Finding\"] = np.where((df[\"Orig_Finding\"]=='nan'),\n",
    "                                 \"\",\n",
    "                                 df[\"Orig_Finding\"])\n",
    "    df[\"Final_Finding\"] =np.where((df[\"Final_Finding\"]=='nan'),\n",
    "                                 \"\",\n",
    "                                 df[\"Final_Finding\"])\n",
    "\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>Accused</th>\n",
       "      <th>Accused_Birth_Year</th>\n",
       "      <th>Accused_Gender</th>\n",
       "      <th>Accused_Race_Code</th>\n",
       "      <th>Date_of_Appt</th>\n",
       "      <th>Current_Unit</th>\n",
       "      <th>Current_Rank</th>\n",
       "      <th>Star</th>\n",
       "      <th>Complaint_Category</th>\n",
       "      <th>Orig_Finding</th>\n",
       "      <th>Orig_Recommended_Discipline</th>\n",
       "      <th>Final_Finding</th>\n",
       "      <th>Final_Recommended_Discipline</th>\n",
       "      <th>FOIA_Request_Number</th>\n",
       "      <th>Report_Produced_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258996</td>\n",
       "      <td>BARRON, WILLIAM</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>M</td>\n",
       "      <td>WHI</td>\n",
       "      <td>1978-02-27</td>\n",
       "      <td>018</td>\n",
       "      <td>SGT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01A-USE OF PROFANITY</td>\n",
       "      <td>NS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>FOIA P046957\\nReport 2.1\\nAll Complaints in CR...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258997</td>\n",
       "      <td>C0NNOLLY, KIMBERLY</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>F</td>\n",
       "      <td>BLK</td>\n",
       "      <td>1990-07-30</td>\n",
       "      <td>055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11026.0</td>\n",
       "      <td>01A-USE OF PROFANITY</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>FOIA P046957\\nReport 2.1\\nAll Complaints in CR...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258997</td>\n",
       "      <td>KEENE, JOHN</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>M</td>\n",
       "      <td>WHI</td>\n",
       "      <td>1999-03-08</td>\n",
       "      <td>153</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01A-USE OF PROFANITY</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>FOIA P046957\\nReport 2.1\\nAll Complaints in CR...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258998</td>\n",
       "      <td>SLAVIN, SCOTT</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>M</td>\n",
       "      <td>WHI</td>\n",
       "      <td>1991-11-18</td>\n",
       "      <td>145</td>\n",
       "      <td>SGT</td>\n",
       "      <td>807.0</td>\n",
       "      <td>10J-NEGLECT OF DUTY/CONDUCT UNBECOMING - ON DUTY</td>\n",
       "      <td>EX</td>\n",
       "      <td>600.0</td>\n",
       "      <td>EX</td>\n",
       "      <td>600.0</td>\n",
       "      <td>FOIA P046957\\nReport 2.1\\nAll Complaints in CR...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259001</td>\n",
       "      <td>MARTINEZ, ANTONIO</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>1996-11-04</td>\n",
       "      <td>701</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10U-INADEQUATE/FAILURE TO PROVIDE SERVICE</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>UN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>FOIA P046957\\nReport 2.1\\nAll Complaints in CR...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRID             Accused  Accused_Birth_Year Accused_Gender  \\\n",
       "0  258996     BARRON, WILLIAM              1949.0              M   \n",
       "1  258997  C0NNOLLY, KIMBERLY              1965.0              F   \n",
       "2  258997         KEENE, JOHN              1968.0              M   \n",
       "3  258998       SLAVIN, SCOTT              1965.0              M   \n",
       "4  259001   MARTINEZ, ANTONIO              1971.0              M   \n",
       "\n",
       "  Accused_Race_Code Date_of_Appt Current_Unit Current_Rank     Star  \\\n",
       "0               WHI   1978-02-27          018          SGT      NaN   \n",
       "1               BLK   1990-07-30          055          NaN  11026.0   \n",
       "2               WHI   1999-03-08          153           PO      NaN   \n",
       "3               WHI   1991-11-18          145          SGT    807.0   \n",
       "4                 S   1996-11-04          701           PO      NaN   \n",
       "\n",
       "                                 Complaint_Category Orig_Finding  \\\n",
       "0                              01A-USE OF PROFANITY           NS   \n",
       "1                              01A-USE OF PROFANITY           UN   \n",
       "2                              01A-USE OF PROFANITY           UN   \n",
       "3  10J-NEGLECT OF DUTY/CONDUCT UNBECOMING - ON DUTY           EX   \n",
       "4         10U-INADEQUATE/FAILURE TO PROVIDE SERVICE           UN   \n",
       "\n",
       "   Orig_Recommended_Discipline Final_Finding  Final_Recommended_Discipline  \\\n",
       "0                        600.0            NS                         600.0   \n",
       "1                        600.0            UN                         600.0   \n",
       "2                        600.0            UN                         600.0   \n",
       "3                        600.0            EX                         600.0   \n",
       "4                        600.0            UN                         600.0   \n",
       "\n",
       "                                 FOIA_Request_Number Report_Produced_Date  \n",
       "0  FOIA P046957\\nReport 2.1\\nAll Complaints in CR...                       \n",
       "1  FOIA P046957\\nReport 2.1\\nAll Complaints in CR...                       \n",
       "2  FOIA P046957\\nReport 2.1\\nAll Complaints in CR...                       \n",
       "3  FOIA P046957\\nReport 2.1\\nAll Complaints in CR...                       \n",
       "4  FOIA P046957\\nReport 2.1\\nAll Complaints in CR...                       "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p046957_-_report_2_-_identified_accused'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_nov_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_nov_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_nov_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p046957 - report 3 - police officer witness data xi.xls']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_nov_2016_report = in_path\n",
    "out_path_nov_2016_report = out_path\n",
    "\n",
    "files = os.listdir(in_path_nov_2016_report)\n",
    "files = [file for file in files if '.xls' in file and 'report 3' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_files = [file.replace(\" \",\"_\").replace(\".xls\",\"\") for file in files]\n",
    "saving_files = saving_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p046957_-_report_3_-_police_officer_witness_data_xi'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Unnamed: 0 Gender Race   Star  Birth Year Date Appointed  \\\n",
      "1   DOLCIMASCOLO, NED      M  WHI    NaN      1945.0     1972-10-23   \n",
      "4      BRYANT, YVONNE      F  BLK    NaN      1956.0     1998-08-31   \n",
      "5      CARROLL, RONDY      M  BLK    NaN      1973.0     1997-08-04   \n",
      "8     CASTILLO, DIEGO      M  WWH   7499      1963.0     1994-07-05   \n",
      "11    RODIRGUEZ, GINA      F  WWH  20045      1964.0     1990-03-26   \n",
      "\n",
      "    Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10    CRID  \n",
      "1          NaN         NaN         NaN         NaN          NaN  259069  \n",
      "4          NaN         NaN         NaN         NaN          NaN  259088  \n",
      "5          NaN         NaN         NaN         NaN          NaN  259088  \n",
      "8          NaN         NaN         NaN         NaN          NaN  259100  \n",
      "11         NaN         NaN         NaN         NaN          NaN  259108  \n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "file=files[0]\n",
    "df = pd.read_excel(in_path_nov_2016_report + file,nrows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "# +1 because of python indexing\n",
    "skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]\n",
    "df = pd.read_excel(in_path_nov_2016_report + file, skiprows=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "\n",
    "## Remove leading and trailing whitespace from columns \n",
    "df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "## Filling Number Column\n",
    "df['CRID'] = pd.to_numeric(df[\"Gender\"],errors='coerce').fillna(method='ffill')\n",
    "df['CRID'] = df['CRID'].astype(int)\n",
    "## Drops end of record \n",
    "df = df.dropna(subset=[\"Unnamed: 0\",\"Gender\",\"Star\"],how=\"all\",axis=0)\n",
    "## Drops CRID only Row\n",
    "df = df[df[\"Gender\"]!=df[\"CRID\"].astype(str)]\n",
    "\n",
    "## drops the significant number of columns that are all nulls\n",
    "df = null_dropper(df)\n",
    "\n",
    "df.columns = [\"Officer_Witness\",\"Officer_Witness_Gender\",\"Officer_Witness_Race\",\"Officer_Witness_Star\",\n",
    "              \"Officer_Witness_Birth_Year\",\"Officer_Witness_Date_Appointed\",\"CRID\"]\n",
    "\n",
    "df = df[[\"CRID\",\"Officer_Witness\",\"Officer_Witness_Gender\",\"Officer_Witness_Race\",\"Officer_Witness_Star\",\n",
    "        \"Officer_Witness_Birth_Year\",\"Officer_Witness_Date_Appointed\"]]\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_nov_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_nov_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_nov_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p046957 - report 4 - victim data.xls']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_nov_2016_report = in_path\n",
    "out_path_nov_2016_report = out_path\n",
    "\n",
    "files = os.listdir(in_path_nov_2016_report)\n",
    "files = [file for file in files if '.xls' in file and 'report 4' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p046957_-_report_4_-_victim_data'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_files = [file.replace(\" \",\"_\").replace(\".xls\",\"\") for file in files]\n",
    "saving_files = saving_files[0]\n",
    "saving_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Number  Unnamed: 1 Gender        Age  Unnamed: 4       Race Desc  \\\n",
      "1  1000009.0         NaN    NaN        NaN         NaN             NaN   \n",
      "2        NaN         NaN      F  37.106849         NaN  WHITE HISPANIC   \n",
      "3        NaN         NaN    NaN        NaN         NaN   end of record   \n",
      "4  1000015.0         NaN    NaN        NaN         NaN             NaN   \n",
      "5        NaN         NaN      F  35.410959         NaN           BLACK   \n",
      "\n",
      "   Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  Unnamed: 11  \n",
      "1         NaN         NaN         NaN         NaN          NaN          NaN  \n",
      "2         NaN         NaN         NaN         NaN          NaN          NaN  \n",
      "3         NaN         NaN         NaN         NaN          NaN          NaN  \n",
      "4         NaN         NaN         NaN         NaN          NaN          NaN  \n",
      "5         NaN         NaN         NaN         NaN          NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "file = files[0]\n",
    "df = pd.read_excel(in_path_nov_2016_report + file,nrows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "# +1 because of python indexing\n",
    "skip = np.where(df.iloc[:,0]==\"Number\")[0][0]+1\n",
    "df = pd.read_excel(in_path_nov_2016_report + file, skiprows=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "## Remove leading and trailing whitespace from columns \n",
    "df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "## Filling Number Column\n",
    "df['Number'].fillna(method='ffill', inplace=True)\n",
    "df['Number'] = df['Number'].astype(int)\n",
    "\n",
    "## Drops end of record \n",
    "df = df.dropna(subset=[\"Gender\",\"Age\",\"Race Desc\"],how=\"all\",axis=0)\n",
    "\n",
    "## drops the significant number of columns that are all nulls\n",
    "df = null_dropper(df)\n",
    "\n",
    "df.columns = [\"CRID\",\"Victim_Gender\",\"Victim_Age\",\"Victim_Race\"]\n",
    "\n",
    "## drop end of record rows\n",
    "df = df[df[\"Victim_Race\"]!=\"end of record\"]\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_nov_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_nov_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_nov_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p046957 - report 5.1 - complainant (reporting party) data.xls',\n",
       " 'p046957 - report 5.2 - complainant (reporting party) data.xls',\n",
       " 'p046957 - report 5.3 - complainant (reporting party) data.xls']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_nov_2016_report = in_path\n",
    "out_path_nov_2016_report = out_path\n",
    "\n",
    "files = os.listdir(in_path_nov_2016_report)\n",
    "files = [file for file in files if '.xls' in file and 'report 5' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p046957_-_report_5_-_complainant_(reporting_party)_data'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_files = [file.replace(\" \",\"_\").replace(\".xls\",\"\") for file in files]\n",
    "saving_files = saving_files[0].replace('.1',\"\")\n",
    "saving_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file,nrows=20)\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = np.where(df.iloc[:,0]==\"Number\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_nov_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    ##print(df.head())\n",
    "    ## Remove leading and trailing whitespace from columns \n",
    "    df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "    ## Filling Number Column\n",
    "    df['Number'].fillna(method='ffill', inplace=True)\n",
    "    df['Number'] = df['Number'].astype(int)\n",
    "\n",
    "    ## Drops end of record \n",
    "    df = df.dropna(subset=[\"Gender\",\"Age\",\"Race Desc\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## drops the significant number of columns that are all nulls\n",
    "    df = null_dropper(df)\n",
    "\n",
    "    df.columns = [\"CRID\",\"Witness_Gender\",\"Witness_Age\",\"Witness_Race\"]\n",
    "\n",
    "    ## drop end of record rows\n",
    "    df = df[df[\"Witness_Race\"]!=\"end of record\"]\n",
    "\n",
    "    ## Adding File Metadata\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''  \n",
    "\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>Witness_Gender</th>\n",
       "      <th>Witness_Age</th>\n",
       "      <th>Witness_Race</th>\n",
       "      <th>FOIA_Request_Number</th>\n",
       "      <th>Report_Produced_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>F</td>\n",
       "      <td>48.767123</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>M</td>\n",
       "      <td>31.641096</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>M</td>\n",
       "      <td>42.621918</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>M</td>\n",
       "      <td>60.254795</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>M</td>\n",
       "      <td>52.750685</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRID Witness_Gender  Witness_Age    Witness_Race  \\\n",
       "0  1000000              F    48.767123           WHITE   \n",
       "1  1000001              M    31.641096           BLACK   \n",
       "2  1000002              M    42.621918  WHITE HISPANIC   \n",
       "3  1000004              M    60.254795        HISPANIC   \n",
       "4  1000004              M    52.750685           WHITE   \n",
       "\n",
       "                                 FOIA_Request_Number Report_Produced_Date  \n",
       "0  FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...           2016-10-29  \n",
       "1  FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...           2016-10-29  \n",
       "2  FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...           2016-10-29  \n",
       "3  FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...           2016-10-29  \n",
       "4  FOIA # P046957\\nReport 5.1\\nComplainant  Data\\...           2016-10-29  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_nov_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_nov_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_nov_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Civis Model",
   "language": "python",
   "name": "civis-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
