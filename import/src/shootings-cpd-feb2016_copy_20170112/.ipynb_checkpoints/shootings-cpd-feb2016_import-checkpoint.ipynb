{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishes General Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_path = \"/your/path/here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complaints-merged-2015_copy_20170112',\n",
       " 'complaints-cpd-2016-dec_copy_20170112',\n",
       " 'complaints-cpd-2016-jun_copy_20170112',\n",
       " 'complaints-cpd-2016-nov_copy_20170112',\n",
       " 'complaints-cpd-2016-oct_copy_20170112',\n",
       " 'complaints-ipra-2016-apr_copy_20170112',\n",
       " 'shootings-cpd-feb2016_copy_20170112',\n",
       " 'shootings-ipra-may2016_copy_20170112',\n",
       " 'TRRs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Data/chicago-police-data/import'\n",
    "db = dropbox_handler()\n",
    "db.list_files(path+'/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = path + '/input/shootings-cpd-feb2016_copy_20170112/'\n",
    "out_path = local_path + '/output/shootings-cpd-feb2016_copy_20170112/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code = db.download_file(path+'/doc/','Location_Code_Dictionary.csv')\n",
    "location_code.dropna(how='all', inplace=True)\n",
    "location_code['Location_Code']=location_code['Location_Code'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Code</th>\n",
       "      <th>Location_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Food Sales/Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tavern/Liquor Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Other Business Establishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Police Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lockup Facility</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location_Code                Location_Value\n",
       "0             1         Food Sales/Restaurant\n",
       "1             2           Tavern/Liquor Store\n",
       "2             3  Other Business Establishment\n",
       "3             4               Police Building\n",
       "4             5               Lockup Facility"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feb 2016 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18A - 1 - Incident(1).xls',\n",
       " '18A - 3 -  Involved Member(1).xls',\n",
       " '18A - 4 -  cpd witness(1).xls',\n",
       " '18A - 5 -  cpd Reporting Party(1).xls',\n",
       " '18a 18b 20a victim-detainee demographics(1).xls',\n",
       " '18b - 1 - Incidents(1).xls',\n",
       " '18b - 3 - Involved Member(1).xls',\n",
       " '18b - 4 - cpd witness(1)Updated Info.xls',\n",
       " '18b - 5 - cpd reporting party(1).xls',\n",
       " '20A - 1 - Incident(1).xls',\n",
       " '20A - 3 -  Involved Member(1).xls',\n",
       " '20A - 4 - cpd Witness(1).xls',\n",
       " '20A - 5 - cpd Reporting Party(1).xls',\n",
       " 'Copy of 18a - 2 - Incident Address(1) Block Level (2)(1)updated.xls',\n",
       " 'Copy of 18b - 2 - incident address(1) block level(1)updated.xls',\n",
       " 'Copy of 20A - 2 - Incident address(1)block level X(2)updated report.xls',\n",
       " 'crms - 05j complaint and investigator(1).xls',\n",
       " 'crms - 05j cpd witness, reporting party, victim(1).xls',\n",
       " 'crms - 05j Officer(1).xls',\n",
       " 'stars for 18a - involved members(1).xls',\n",
       " 'stars for 18b - involved members(1).xls',\n",
       " 'stars for 20a - involved members(1).xls']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_feb_2016_report = in_path\n",
    "out_path_feb_2016_report = out_path\n",
    "\n",
    "files = [x for x in db.list_files(in_path_feb_2016_report) if '.xls' in x]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 1 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    ##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing, +1 because of header in first df\n",
    "    skip = np.where(df.iloc[:,0]==\"Log No\")[0][0]+1\n",
    "    ##df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    ## remove end of record rows and page number row\n",
    "    df = df.dropna(subset=[\"Log No\",\"Assignment\",\"Initial Category\",\"Assigned Team\"],how=\"all\",axis=0)\n",
    "    \n",
    "    df.columns = [\"CRID\",\"Assignment\",\"Initial_Category\",\"Assigned_Team\",\"Team_Assigned_Date\",\n",
    "                  \"Investigator_Assigned\",\"Investigator_Assigned_Date\",\"Supervisor_Assigned\",\"IPRA_Closed_Date\"]\n",
    "\n",
    "    df[\"Team_Assigned_Date\"] = pd.to_datetime(df[\"Team_Assigned_Date\"],format=\"%Y%m%d %H:%M\",errors='coerce')\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    \n",
    "    ## Adding File Metadata\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''    \n",
    "\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_files = \"1_-_Incident(1)\"\n",
    "\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 2 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    ##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    try:\n",
    "        df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\"]\n",
    "    except:\n",
    "        df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Number\",\"Incident_Address\",\"District\"]\n",
    "        df[\"Incident_Address\"] = df[[\"Incident_Number\",\"Incident_Address\"]].apply(lambda x: ' '.join(x), axis=1)\n",
    "        df = df[[\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\"]]\n",
    "    \n",
    "    ## Split Up Date into Start and End Date\n",
    "    df1 = df[\"Incident_Date\"].str.split(\" - \",expand=True)\n",
    "    df = df.merge(df1,how='left',right_index=True,left_index=True)\n",
    "    \n",
    "    df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\",\"Incident_Start_Date\",\"Incident_End_Date\"]\n",
    "    df[\"Incident_Start_Date\"] = pd.to_datetime(df[\"Incident_Start_Date\"],format=\"%d-%b-%Y %H:%M\",errors='coerce')\n",
    "    df[\"Incident_End_Date\"] = pd.to_datetime(df[\"Incident_End_Date\"],format=\"%d-%b-%Y %H:%M\",errors='coerce')\n",
    "    \n",
    "    ## Split up address into all the relevant fields\n",
    "    df2 = df[\"Incident_Address\"].str.split(\",\",expand=True)\n",
    "    def row_switcher(row):\n",
    "        if row[3] is None:\n",
    "            row[3]=row[2]\n",
    "            row[2]=row[1]\n",
    "            row[1]=None\n",
    "        return row\n",
    "\n",
    "    if df2.shape[1]==4:\n",
    "        df2 = df2.apply(row_switcher,axis=1)\n",
    "        max_val = df2.shape[1]-1\n",
    "        df3 = df2[max_val].str.strip().str.split(\" \",expand=True)\n",
    "        df2 = df2.merge(df3,left_index=True,right_index=True)\n",
    "        df2.columns = [\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"State_Zip\",\"Incident_State\",\"Incident_Zip\"]\n",
    "        df2 = df2[[\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"Incident_State\",\"Incident_Zip\"]]\n",
    "    else:\n",
    "        df2[3]=None\n",
    "        df2 = df2[[0,3,1,2]]\n",
    "        df2.columns = [0,1,2,3]\n",
    "        max_val = df2.shape[1]-1\n",
    "        df3 = df2[max_val].str.strip().str.split(\" \",expand=True)\n",
    "        df2 = df2.merge(df3,left_index=True,right_index=True)\n",
    "        df2.columns = [\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"State_Zip\",\"Incident_State\",\"Incident_Zip\"]\n",
    "        df2 = df2[[\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"Incident_State\",\"Incident_Zip\"]]\n",
    "    \n",
    "    df = df.merge(df2,left_index=True,right_index=True)\n",
    "    df = df[[\"CRID\",\"Incident_Date\",\"Incident_Address_y\",\"Incident_Apt\",\n",
    "             \"Incident_City\",\"Incident_State\",\"Incident_Zip\",\"District\",\n",
    "             \"Incident_Start_Date\",\"Incident_End_Date\"]]\n",
    "    df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"Incident_Apt\",\n",
    "             \"Incident_City\",\"Incident_State\",\"Incident_Zip\",\"District\",\n",
    "             \"Incident_Start_Date\",\"Incident_End_Date\"]\n",
    "\n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"Incident_Address(1)_Block_Level\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 3 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Involved_Officer\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"Involved_Member(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 4 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Officer_Witness\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"CPD_Witness(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 5 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Officer_Reporting_Party\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"CPD_Reporting_Party(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Files In Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "done_list = ['- 1 -','- 2 -','- 3 -','- 4 -','- 5 -']\n",
    "done_files = [item for item in files if any(x in item for x in done_list)]\n",
    "other_files = [file for file in files if file not in done_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18a 18b 20a victim-detainee demographics(1).xls',\n",
       " 'crms - 05j complaint and investigator(1).xls',\n",
       " 'crms - 05j cpd witness, reporting party, victim(1).xls',\n",
       " 'crms - 05j Officer(1).xls',\n",
       " 'stars for 18a - involved members(1).xls',\n",
       " 'stars for 18b - involved members(1).xls',\n",
       " 'stars for 20a - involved members(1).xls']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim Detainee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = other_files[0]\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "# had to check file as it doesn't contain any relevant headers\n",
    "skip = 7\n",
    "#df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "df.columns = [\"CRID\",\"Detainee_Age\",\"Detainee_Gender\",\"Detainee_Race\"]\n",
    "df['CRID'].fillna(method='ffill', inplace=True)\n",
    "df['CRID'] = df['CRID'].astype(int)\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "\n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"victim-detainee_demographics(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star_files = [file for file in other_files if 'stars' in file]\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "for file in star_files:\n",
    "    ##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # distinct header\n",
    "    try:\n",
    "        skip = df[df.iloc[:,1].str.contains(\"PERS_LAST_NME\")==True].index.values[0]+1+1\n",
    "    except:\n",
    "        skip = df[df.iloc[:,2].str.contains(\"PERS_LAST_NME\")==True].index.values[0]+1+1\n",
    "    #df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"Officer_Last_Name\",\"Officer_First_Name\",\"Star\",\"Officer_Description\"]\n",
    " \n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saving_file = \"stars-for_involved_members(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complaint & Investigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = other_files[1]\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "FOIA_Request = [x for x in df.iloc[0,:].astype(str).tolist() if 'FOIA' in x][0]\n",
    "# had to check file as it doesn't contain any relevant headers\n",
    "skip = 12\n",
    "#df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].replace(\"Beat:\",None)\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].replace(\"Incident Date/Time:\",None)\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].replace(\"Investigator:\",None)\n",
    "\n",
    "df['Unnamed: 0'].fillna(method='ffill', inplace=True)\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n",
    "\n",
    "df.dropna(subset=['Unnamed: 1','Unnamed: 2',\"Unnamed: 3\",\"Unnamed: 4\"], how='all', inplace=True)\n",
    "\n",
    "df1=df.loc[:,['Unnamed: 0','Unnamed: 1',\"Unnamed: 3\",\"Unnamed: 4\",'Unnamed: 5',\n",
    "        'Unnamed: 7','Unnamed: 8','Unnamed: 10']]\n",
    "df1.dropna(subset=['Unnamed: 1',\"Unnamed: 10\"], how='all', inplace=True)\n",
    "df1.columns = ['CRID','Beat','Block','Location','Street','City','State','Location_Value']\n",
    "\n",
    "df2 =df.loc[:,['Unnamed: 0','Unnamed: 2','Unnamed: 6']]\n",
    "df2.dropna(subset=['Unnamed: 0','Unnamed: 2',\"Unnamed: 6\"], how='any', inplace=True)\n",
    "df2.columns = ['CRID','Incident_Date','Complaint_Date']\n",
    "df2 = df2[df2['Complaint_Date']!='Investigator End Date:']\n",
    "\n",
    "df3 = df.loc[:,['Unnamed: 0','Unnamed: 2','Unnamed: 4','Unnamed: 8']]\n",
    "df3.dropna(subset=['Unnamed: 0','Unnamed: 2',\"Unnamed: 4\",'Unnamed: 8'], how='all', inplace=True)\n",
    "df3.columns = ['CRID','Investigator','Assigned_Date','Investigator_End_Date']\n",
    "\n",
    "## Every 3rd row contains the correct data\n",
    "df3 = df3.iloc[2::3,:]\n",
    "\n",
    "df4 = df1.merge(df2,how='left',right_on='CRID',left_on='CRID')\n",
    "df4 = df4.merge(df3,how='left',right_on='CRID',left_on='CRID')\n",
    "\n",
    "df4['Block'] = df4['Block'].astype(str)\n",
    "df4[\"Incident_Address\"] = df4[[\"Block\",\"Location\",\"Street\"]].apply(lambda x: ' '.join(x), axis=1)\n",
    "df5 = df4['Location_Value'].str.split(' - ',n=1,expand=True)\n",
    "df5.columns=['Location_Code','Location_Value']\n",
    "df = df4.merge(df5,how='left',right_index=True,left_index=True)\n",
    "\n",
    "df = df[['CRID','Beat','Incident_Address','City','State','Location_Code','Location_Value_y',\n",
    "         'Incident_Date','Complaint_Date','Investigator','Assigned_Date','Investigator_End_Date']]\n",
    "\n",
    "df.columns = ['CRID','Beat','Incident_Address','City','State','Location_Code','Location_Value',\n",
    "         'Incident_Date','Complaint_Date','Investigator','Assigned_Date','Investigator_End_Date']\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "\n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saving_file = \"crms_-_05j_complaint_and_investigator(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Witness Reporting Party, and Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = other_files[2]\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "FOIA_Request = [x for x in df.iloc[0,:].astype(str).tolist() if 'FOIA' in x][0]\n",
    "# had to check file as it doesn't contain any relevant headers\n",
    "skip = 8\n",
    "#df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "\n",
    "df['CRID'] = df.iloc[df['Unnamed: 0'].astype(str).str.isnumeric().tolist(),0]\n",
    "df['Values'] = df[~df.isin(df1)]['Unnamed: 0']\n",
    "\n",
    "df['CRID'].fillna(method='ffill', inplace=True)\n",
    "df['CRID'] = df['CRID'].astype(int)\n",
    "df.dropna(subset=['Role','CPD or Not','Gender','Ethicity','Year of Birth','Star','Position','Values'],\n",
    "          how='all',inplace=True)\n",
    "\n",
    "df = df[['CRID','Values','Role','CPD or Not','Gender','Ethicity','Year of Birth','Star','Position']]\n",
    "df.columns = ['CRID','Values','Role','CPD_or_Not','Gender','Ethnicity','Year of Birth','Star','Position']\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "\n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saving_file = \"crms_-_05j_cpd_witness,_reporting_party,_victim(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Officer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = other_files[3]\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "##df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "df = db.download_file(in_path_feb_2016_report,file,rows=20)\n",
    "## Making Sure Every File contains date the file was created and the foia that created it\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "\n",
    "FOIA_Request = [x for x in df.iloc[0,:].astype(str).tolist() if 'FOIA' in x][0]\n",
    "# had to check file as it doesn't contain any relevant headers\n",
    "skip = 11\n",
    "#df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "df = db.download_file(in_path_feb_2016_report,file,skip=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df['Unnamed: 0'].fillna(method='ffill', inplace=True)\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n",
    "\n",
    "df['Unnamed: 1'] = df['Unnamed: 1'].replace(\"Accused:\",None)\n",
    "df['Unnamed: 2'] = df['Unnamed: 2'].replace(\"Accused Unit:\",None)\n",
    "df['Unnamed: 3'] = df['Unnamed: 3'].replace(\"Recom Finding:\",None)\n",
    "df['Unnamed: 3'] = df['Unnamed: 3'].replace(\"Recom Action:\",None)\n",
    "df['Unnamed: 9'] = df['Unnamed: 9'].replace(\"Rank:\",None)\n",
    "df['Unnamed: 14'] = df['Unnamed: 14'].replace(\"Star:\",None)\n",
    "df['Unnamed: 16'] = df['Unnamed: 16'].replace(\"Final Finding:\",None)\n",
    "df['Unnamed: 16'] = df['Unnamed: 16'].replace(\"Final Action:\",None)\n",
    "df['Unnamed: 18'] = df['Unnamed: 18'].replace(\"Gender:\",None)\n",
    "df['Unnamed: 22'] = df['Unnamed: 22'].replace(\"Date of Appointment:\",None)\n",
    "df['Unnamed: 24'] = df['Unnamed: 24'].replace(\"Ethnicity:\",None)\n",
    "df['Unnamed: 31'] = df['Unnamed: 31'].replace(\"Year of Birth:\",None)\n",
    "\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "\n",
    "df.dropna(subset=['Unnamed: 4','Unnamed: 6','Unnamed: 8','Unnamed: 11',\"Unnamed: 15\",\n",
    "                  'Unnamed: 20','Unnamed: 21','Unnamed: 26','Unnamed: 28'\n",
    "                  ,'Unnamed: 32'],how='all', inplace=True)\n",
    "\n",
    "df['Unnamed: 4'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "df1=df.loc[:,['Unnamed: 0','Unnamed: 4',\"Unnamed: 15\",\"Unnamed: 21\",'Unnamed: 26',\n",
    "        'Unnamed: 32']]\n",
    "df1.dropna(subset=[\"Unnamed: 15\",'Unnamed: 21','Unnamed: 26','Unnamed: 32'], how='all', inplace=True)\n",
    "df1.columns = ['CRID','Officer','Star','Gender','Race','Age',]\n",
    "\n",
    "df2 =df.loc[:,['Unnamed: 0','Unnamed: 4','Unnamed: 6','Unnamed: 11','Unnamed: 28']]\n",
    "df2.dropna(subset=['Unnamed: 6','Unnamed: 11',\"Unnamed: 28\"], how='all', inplace=True)\n",
    "df2.columns = ['CRID','Officer','Unit','Position','Appointment_Date']\n",
    "\n",
    "df3 = df.loc[:,['Unnamed: 0','Unnamed: 4','Unnamed: 8','Unnamed: 20']]\n",
    "df3.dropna(subset=['Unnamed: 8',\"Unnamed: 20\"], how='all', inplace=True)\n",
    "df3.columns = ['CRID','Officer','Recommended_Finding','Final_Finding']\n",
    "## Finding and action are under each other\n",
    "df4=df3.iloc[::2,:]\n",
    "df5=df3.iloc[1::2,:]\n",
    "df5.columns =['CRID','Officer','Recommended_Action','Final_Action']\n",
    "df4 = df4.merge(df5,how='left',on=['CRID','Officer'])\n",
    "\n",
    "dff = df1.merge(df2,how='left',on=['CRID','Officer'])\n",
    "dff = dff.merge(df4,how='left',on=['CRID','Officer'])\n",
    "\n",
    "df = dff\n",
    "\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "\n",
    "final_df = final_df.append(df)\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"crms_-_05j_Officer(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\"_metadata.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Civis Model",
   "language": "python",
   "name": "civis-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
