{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that help with the magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can be used to remove columns that are all nulls so you don't have to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_dropper(df):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    info_values = [x[0] for x in info_values if x[1].startswith('0 non-null')]\n",
    "    df = df.drop(info_values,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates metadata as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metadata_dataset(df,file):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    metadata_df = pd.DataFrame(info_values)\n",
    "    metadata_df[\"File\"] = file\n",
    "    metadata_df.columns = [\"Column_Name\",\"Column_Info\",\"Original_Dataset\"]\n",
    "    ## Column Info Split\n",
    "    metadata_df['Non_Null_Count'], metadata_df['Object_Type'] = metadata_df['Column_Info'].str.split(' ', 1).str\n",
    "    metadata_df[\"Object_Type\"] = metadata_df[\"Object_Type\"].str.replace(\"non-null \",\"\")\n",
    "    ## unique counts for each variable\n",
    "    uniques_df = df.apply(lambda x: len(x.unique())).reset_index()\n",
    "    uniques_df.columns = [\"Column_Name\",\"Unique_Count\"]\n",
    "    metadata_df[\"Unique_Count\"] = uniques_df[\"Unique_Count\"]\n",
    "    metadata_df = metadata_df[[\"Original_Dataset\",\"Column_Name\",\"Non_Null_Count\",\"Unique_Count\",\"Object_Type\"]]\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts single column named City_State_Zip into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def city_state_zip_splitter(df):\n",
    "    new_states_list=[]\n",
    "    for value in df[\"City_State_Zip\"]:\n",
    "        ## check if it contains a number (zipcode)\n",
    "        if hasNumbers(value):\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 3 values\n",
    "            while len(split_state)>3:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        else:\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 2 values\n",
    "            while len(split_state)>2:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        new_states_list.append(split_state)\n",
    "    city_state_zip =  pd.DataFrame(new_states_list)\n",
    "    city_state_zip.columns = [\"City\",\"State\",\"Zip\"]\n",
    "    return city_state_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishes General Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/thudson/Documents/Github/chicago-police-data/import\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = path + '/input/shootings-cpd-feb2016_copy_20170112/'\n",
    "out_path =path + '/output/shootings-cpd-feb2016_copy_20170112/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code = pd.read_csv(path+'/doc/Location_Code_Dictionary.csv')\n",
    "location_code.dropna(how='all', inplace=True)\n",
    "location_code['Location_Code']=location_code['Location_Code'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Code</th>\n",
       "      <th>Location_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Food Sales/Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tavern/Liquor Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Other Business Establishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Police Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lockup Facility</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location_Code                Location_Value\n",
       "0             1         Food Sales/Restaurant\n",
       "1             2           Tavern/Liquor Store\n",
       "2             3  Other Business Establishment\n",
       "3             4               Police Building\n",
       "4             5               Lockup Facility"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feb 2016 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18A - 1 - Incident(1).xls',\n",
       " '18A - 3 -  Involved Member(1).xls',\n",
       " '18A - 4 -  cpd witness(1).xls',\n",
       " '18A - 5 -  cpd Reporting Party(1).xls',\n",
       " '18a 18b 20a victim-detainee demographics(1).xls',\n",
       " '18b - 1 - Incidents(1).xls',\n",
       " '18b - 3 - Involved Member(1).xls',\n",
       " '18b - 4 - cpd witness(1)Updated Info.xls',\n",
       " '18b - 5 - cpd reporting party(1).xls',\n",
       " '20A - 1 - Incident(1).xls',\n",
       " '20A - 3 -  Involved Member(1).xls',\n",
       " '20A - 4 - cpd Witness(1).xls',\n",
       " '20A - 5 - cpd Reporting Party(1).xls',\n",
       " 'Copy of 18a - 2 - Incident Address(1) Block Level (2)(1)updated.xls',\n",
       " 'Copy of 18b - 2 - incident address(1) block level(1)updated.xls',\n",
       " 'Copy of 20A - 2 - Incident address(1)block level X(2)updated report.xls',\n",
       " 'crms - 05j complaint and investigator(1).xls',\n",
       " 'crms - 05j cpd witness, reporting party, victim(1).xls',\n",
       " 'crms - 05j Officer(1).xls',\n",
       " 'stars for 18a - involved members(1).xls',\n",
       " 'stars for 18b - involved members(1).xls',\n",
       " 'stars for 20a - involved members(1).xls']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_feb_2016_report = in_path\n",
    "out_path_feb_2016_report = out_path\n",
    "\n",
    "files = [x for x in os.listdir(in_path_feb_2016_report) if '.xls' in x]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 1 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing, +1 because of header in first df\n",
    "    skip = np.where(df.iloc[:,0]==\"Log No\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    ## remove end of record rows and page number row\n",
    "    df = df.dropna(subset=[\"Log No\",\"Assignment\",\"Initial Category\",\"Assigned Team\"],how=\"all\",axis=0)\n",
    "    \n",
    "    df.columns = [\"CRID\",\"Assignment\",\"Initial_Category\",\"Assigned_Team\",\"Team_Assigned_Date\",\n",
    "                  \"Investigator_Assigned\",\"Investigator_Assigned_Date\",\"Supervisor_Assigned\",\"IPRA_Closed_Date\"]\n",
    "\n",
    "    df[\"Team_Assigned_Date\"] = pd.to_datetime(df[\"Team_Assigned_Date\"],format=\"%Y%m%d %H:%M\",errors='coerce')\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    \n",
    "    ## Adding File Metadata\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''    \n",
    "\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_files = \"1_-_Incident(1)\"\n",
    "\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_files+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_files+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_files+\"_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 2 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    try:\n",
    "        df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\"]\n",
    "    except:\n",
    "        df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Number\",\"Incident_Address\",\"District\"]\n",
    "        df[\"Incident_Address\"] = df[[\"Incident_Number\",\"Incident_Address\"]].apply(lambda x: ' '.join(x), axis=1)\n",
    "        df = df[[\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\"]]\n",
    "    \n",
    "    ## Split Up Date into Start and End Date\n",
    "    df1 = df[\"Incident_Date\"].str.split(\" - \",expand=True)\n",
    "    df = df.merge(df1,how='left',right_index=True,left_index=True)\n",
    "    \n",
    "    df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"District\",\"Incident_Start_Date\",\"Incident_End_Date\"]\n",
    "    df[\"Incident_Start_Date\"] = pd.to_datetime(df[\"Incident_Start_Date\"],format=\"%d-%b-%Y %H:%M\",errors='coerce')\n",
    "    df[\"Incident_End_Date\"] = pd.to_datetime(df[\"Incident_End_Date\"],format=\"%d-%b-%Y %H:%M\",errors='coerce')\n",
    "    \n",
    "    ## Split up address into all the relevant fields\n",
    "    df2 = df[\"Incident_Address\"].str.split(\",\",expand=True)\n",
    "    def row_switcher(row):\n",
    "        if row[3] is None:\n",
    "            row[3]=row[2]\n",
    "            row[2]=row[1]\n",
    "            row[1]=None\n",
    "        return row\n",
    "\n",
    "    if df2.shape[1]==4:\n",
    "        df2 = df2.apply(row_switcher,axis=1)\n",
    "        max_val = df2.shape[1]-1\n",
    "        df3 = df2[max_val].str.strip().str.split(\" \",expand=True)\n",
    "        df2 = df2.merge(df3,left_index=True,right_index=True)\n",
    "        df2.columns = [\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"State_Zip\",\"Incident_State\",\"Incident_Zip\"]\n",
    "        df2 = df2[[\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"Incident_State\",\"Incident_Zip\"]]\n",
    "    else:\n",
    "        df2[3]=None\n",
    "        df2 = df2[[0,3,1,2]]\n",
    "        df2.columns = [0,1,2,3]\n",
    "        max_val = df2.shape[1]-1\n",
    "        df3 = df2[max_val].str.strip().str.split(\" \",expand=True)\n",
    "        df2 = df2.merge(df3,left_index=True,right_index=True)\n",
    "        df2.columns = [\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"State_Zip\",\"Incident_State\",\"Incident_Zip\"]\n",
    "        df2 = df2[[\"Incident_Address\",\"Incident_Apt\",\"Incident_City\",\"Incident_State\",\"Incident_Zip\"]]\n",
    "    \n",
    "    df = df.merge(df2,left_index=True,right_index=True)\n",
    "    df = df[[\"CRID\",\"Incident_Date\",\"Incident_Address_y\",\"Incident_Apt\",\n",
    "             \"Incident_City\",\"Incident_State\",\"Incident_Zip\",\"District\",\n",
    "             \"Incident_Start_Date\",\"Incident_End_Date\"]]\n",
    "    df.columns = [\"CRID\",\"Incident_Date\",\"Incident_Address\",\"Incident_Apt\",\n",
    "             \"Incident_City\",\"Incident_State\",\"Incident_Zip\",\"District\",\n",
    "             \"Incident_Start_Date\",\"Incident_End_Date\"]\n",
    "\n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"Incident_Address(1)_Block_Level\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 3 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Involved_Officer\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"Involved_Member(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 4 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Officer_Witness\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Dataset</th>\n",
       "      <th>Column_Name</th>\n",
       "      <th>Non_Null_Count</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Object_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18A - 4 -  cpd witness(1).xls</td>\n",
       "      <td>CRID</td>\n",
       "      <td>131</td>\n",
       "      <td>45</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18A - 4 -  cpd witness(1).xls</td>\n",
       "      <td>Officer_Witness</td>\n",
       "      <td>131</td>\n",
       "      <td>128</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18A - 4 -  cpd witness(1).xls</td>\n",
       "      <td>FOIA_Request_Number</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18A - 4 -  cpd witness(1).xls</td>\n",
       "      <td>Report_Produced_Date</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18b - 4 - cpd witness(1)Updated Info.xls</td>\n",
       "      <td>CRID</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18b - 4 - cpd witness(1)Updated Info.xls</td>\n",
       "      <td>Officer_Witness</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18b - 4 - cpd witness(1)Updated Info.xls</td>\n",
       "      <td>FOIA_Request_Number</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18b - 4 - cpd witness(1)Updated Info.xls</td>\n",
       "      <td>Report_Produced_Date</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20A - 4 - cpd Witness(1).xls</td>\n",
       "      <td>CRID</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20A - 4 - cpd Witness(1).xls</td>\n",
       "      <td>Officer_Witness</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20A - 4 - cpd Witness(1).xls</td>\n",
       "      <td>FOIA_Request_Number</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20A - 4 - cpd Witness(1).xls</td>\n",
       "      <td>Report_Produced_Date</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Original_Dataset           Column_Name  \\\n",
       "0              18A - 4 -  cpd witness(1).xls                  CRID   \n",
       "1              18A - 4 -  cpd witness(1).xls       Officer_Witness   \n",
       "2              18A - 4 -  cpd witness(1).xls   FOIA_Request_Number   \n",
       "3              18A - 4 -  cpd witness(1).xls  Report_Produced_Date   \n",
       "4   18b - 4 - cpd witness(1)Updated Info.xls                  CRID   \n",
       "5   18b - 4 - cpd witness(1)Updated Info.xls       Officer_Witness   \n",
       "6   18b - 4 - cpd witness(1)Updated Info.xls   FOIA_Request_Number   \n",
       "7   18b - 4 - cpd witness(1)Updated Info.xls  Report_Produced_Date   \n",
       "8               20A - 4 - cpd Witness(1).xls                  CRID   \n",
       "9               20A - 4 - cpd Witness(1).xls       Officer_Witness   \n",
       "10              20A - 4 - cpd Witness(1).xls   FOIA_Request_Number   \n",
       "11              20A - 4 - cpd Witness(1).xls  Report_Produced_Date   \n",
       "\n",
       "   Non_Null_Count  Unique_Count Object_Type  \n",
       "0             131            45       int64  \n",
       "1             131           128      object  \n",
       "2             131             1      object  \n",
       "3             131             1      object  \n",
       "4               6             2       int64  \n",
       "5               5             6      object  \n",
       "6               6             1      object  \n",
       "7               6             1      object  \n",
       "8              47            32       int64  \n",
       "9              47            46      object  \n",
       "10             47             1      object  \n",
       "11             47             1      object  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"CPD_Witness(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incident_files = [file for file in files if '- 5 -' in file]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in incident_files:\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = [x for x in col_list if isinstance(x, datetime.datetime)]\n",
    "    col_list = [x for x in col_list if isinstance(x, datetime.datetime)==False]\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing\n",
    "    skip = df[df.iloc[:,0].str.contains(\"Log No\")==True].index.values[0]+1\n",
    "    df = pd.read_excel(in_path_feb_2016_report + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    ## Drop all null columns\n",
    "    df = null_dropper(df)\n",
    "    df.columns = [\"CRID\",\"Officer_Reporting_Party\"]\n",
    "    \n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df[\"CRID\"] = df[\"CRID\"].astype(int)\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date[0].date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    \n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saving_file = \"CPD_Reporting_Party(1)\"\n",
    "final_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)\n",
    "final_df.to_excel(out_path_feb_2016_report+saving_file+\".xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_feb_2016_report+saving_file+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Files In Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Civis Model",
   "language": "python",
   "name": "civis-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
