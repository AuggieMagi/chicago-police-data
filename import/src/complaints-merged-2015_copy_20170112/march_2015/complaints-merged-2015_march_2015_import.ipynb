{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that help with the magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can be used to remove columns that are all nulls so you don't have to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_dropper(df):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    info_values = [x[0] for x in info_values if x[1].startswith('0 non-null')]\n",
    "    df = df.drop(info_values,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates metadata as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metadata_dataset(df,file):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    metadata_df = pd.DataFrame(info_values)\n",
    "    metadata_df[\"File\"] = file\n",
    "    metadata_df.columns = [\"Column_Name\",\"Column_Info\",\"Original_Dataset\"]\n",
    "    ## Column Info Split\n",
    "    metadata_df['Non_Null_Count'], metadata_df['Object_Type'] = metadata_df['Column_Info'].str.split(' ', 1).str\n",
    "    metadata_df[\"Object_Type\"] = metadata_df[\"Object_Type\"].str.replace(\"non-null \",\"\")\n",
    "    ## unique counts for each variable\n",
    "    uniques_df = df.apply(lambda x: len(x.unique())).reset_index()\n",
    "    uniques_df.columns = [\"Column_Name\",\"Unique_Count\"]\n",
    "    metadata_df[\"Unique_Count\"] = uniques_df[\"Unique_Count\"]\n",
    "    metadata_df = metadata_df[[\"Original_Dataset\",\"Column_Name\",\"Non_Null_Count\",\"Unique_Count\",\"Object_Type\"]]\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts single column named City_State_Zip into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def city_state_zip_splitter(df):\n",
    "    new_states_list=[]\n",
    "    for value in df[\"City_State_Zip\"]:\n",
    "        ## check if it contains a number (zipcode)\n",
    "        if hasNumbers(value):\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 3 values\n",
    "            while len(split_state)>3:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        else:\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 2 values\n",
    "            while len(split_state)>2:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        new_states_list.append(split_state)\n",
    "    city_state_zip =  pd.DataFrame(new_states_list)\n",
    "    city_state_zip.columns = [\"City\",\"State\",\"Zip\"]\n",
    "    return city_state_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishes General Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/thudson/Documents/Github/chicago-police-data/import\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = path + '/input/complaints-merged-2015_copy_20170112'\n",
    "out_path =path + '/output/complaints-merged-2015_copy_20170112'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code = pd.read_csv(path+'/doc/Location_Code_Dictionary.csv')\n",
    "location_code.dropna(how='all', inplace=True)\n",
    "location_code['Location_Code']=location_code['Location_Code'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## March 2015 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foia 14-5509 - report 1a - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1b - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1c - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1d - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1e - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1f - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1g - all complaints in time frame.xls',\n",
       " 'foia 14-5509 - report 1h - all complaints in time frame.xls']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_mar_2015_report1 = in_path+'/march_2015/Report_1_-_All_Complaints_in_Time_Frame/'\n",
    "out_path_mar_2015_report1 = out_path+'/march_2015/Report_1_-_All_Complaints_in_Time_Frame/'\n",
    "\n",
    "files = os.listdir(in_path_mar_2015_report1)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in files:    \n",
    "    df = pd.read_excel(in_path_mar_2015_report1 + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = col_list.pop()\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "    # +1 because of python indexing, +1 because of header in first df\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1+1\n",
    "    df = pd.read_excel(in_path_mar_2015_report1 + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    ## remove end of record rows and page number row\n",
    "    df = df.dropna(subset=[\"Number:\",\"Beat:\",\"Location Code:\",\"Address of Incident:\",\"Unnamed: 6\"\n",
    "                     ,\"Unnamed: 9\",\"Unnamed: 10\",\"Unnamed: 11\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## Need to move Investigator Name to Col 12\n",
    "    df['Number:'].fillna(method='ffill', inplace=True)\n",
    "    df['Number:'] = df['Number:'].astype(int)\n",
    "\n",
    "    ## Investigator Rows have all others as null\n",
    "    df1 = df[df[\"Unnamed: 1\"].isnull() & \n",
    "       df[\"Beat:\"].isnull() & \n",
    "       df[\"Location Code:\"].isnull() & \n",
    "       df[\"Unnamed: 9\"].isnull() &\n",
    "       df[\"Unnamed: 10\"].isnull()].loc[:,(\"Number:\",\"Unnamed: 11\")]\n",
    "\n",
    "    df1.columns=[\"Number:\",\"Investigator:\"]\n",
    "\n",
    "    ## Merge Back Rows \n",
    "    df2 = df.merge(df1,how=\"left\",on=\"Number:\")\n",
    "\n",
    "    ## Drop Original all null Investigator Rows\n",
    "    df2 = df2.dropna(subset=[\"Beat:\",\"Location Code:\",\"Address of Incident:\",\"Unnamed: 5\",\"Unnamed: 6\"\n",
    "                     ,\"Unnamed: 9\",\"Unnamed: 10\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## Replace ---- with empty strings\n",
    "    df2 = df2.replace('----', \"\").replace('-----', \"\")\n",
    "    ## Drop all null columns\n",
    "    df2 = null_dropper(df2)\n",
    "\n",
    "    ## Covert Address Columns into single column\n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].astype(str)\n",
    "    df2[\"Unnamed: 5\"] = df2['Unnamed: 5'].astype(str)\n",
    "    df2[\"Unnamed: 6\"] = df2['Unnamed: 6'].astype(str)\n",
    "    df2[\"Unnamed: 7\"] = df2['Unnamed: 7'].astype(str)\n",
    "\n",
    "    df2[\"Address of Incident:\"] = df2[[\"Address of Incident:\",\"Unnamed: 5\", \"Unnamed: 6\"]].apply(lambda x: ' '.join(x), axis=1)\n",
    "    \n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].str.replace(\"nan\",\"\")\n",
    "    df2[\"Address of Incident:\"] = df2['Address of Incident:'].str.strip()\n",
    "    \n",
    "    df2 = df2[[\"Number:\",\"Beat:\",\"Location Code:\",\"Address of Incident:\",\"Unnamed: 7\",\n",
    "               \"Unnamed: 9\",\"Unnamed: 10\", \"Unnamed: 11\",\"Investigator:\"]]\n",
    "\n",
    "    df2.columns = [\"CRID\",\"Beat\",\"Location_Code\",\"Address_of_Incident\",\n",
    "                      \"City_State_Zip\",\"Incident_Date\",\"Complaint_Date\", \n",
    "                      \"Closed_Date\",\"Investigator\"]\n",
    "\n",
    "    ## Splitting City State Zip into three columns\n",
    "    city_state_zip = city_state_zip_splitter(df2)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    df2 = df2.merge(city_state_zip,how='left',right_index=True,left_index=True)\n",
    "    ## Appending Location Type\n",
    "    df2 = df2.merge(location_code,how='left',on='Location_Code')\n",
    "    \n",
    "    df2 = df2 [[\"CRID\",\"Beat\",\"Location_Code\",\"Location_Value\",\"Address_of_Incident\",\n",
    "                      \"City\",\"State\",\"Zip\",\"Incident_Date\",\"Complaint_Date\", \n",
    "                      \"Closed_Date\",\"Investigator\"]]\n",
    "    \n",
    "    ## Adding File Metadata\n",
    "    df2[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''  \n",
    "    ## Appending to Final File + Metadata\n",
    "    final_df = final_df.append(df2)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df2,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_mar_2015_report1+\"foia_14-5509_-_report_1.csv\",index=False)\n",
    "final_df.to_excel(out_path_mar_2015_report1+\"foia_14-5509_-_report_1.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_mar_2015_report1+\"foia_14-5509_-_report_1_metadata.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foia 14-5509 - report 2a - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2b - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2c - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2d - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2e - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2f - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2g - identified accused xi.xls',\n",
       " 'foia 14-5509 - report 2h - identified accused xi.xls']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_mar_2015_report2 = in_path+'/march_2015/Report_2_-_Identified_Accused/'\n",
    "out_path_mar_2015_report2 = out_path+'/march_2015/Report_2_-_Identified_Accused/'\n",
    "\n",
    "files = os.listdir(in_path_mar_2015_report2)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_excel(in_path_mar_2015_report2 + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = col_list.pop()\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "    # +1 because of python indexing, +1 because of header in first df\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1+1\n",
    "    df = pd.read_excel(in_path_mar_2015_report2 + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    ## Remove leading and trailing whitespace from columns \n",
    "    df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "    ## Need to fill in Number\n",
    "    df['Number:'].fillna(method='ffill', inplace=True)\n",
    "    df['Number:'] = df['Number:'].astype(int)\n",
    "\n",
    "    ## Drops end of record \n",
    "    df = df.dropna(subset=[\"Accused:\",\"Gender:\",\"Date of Appt:\",\"Star:\"],how=\"all\",axis=0)\n",
    "    \n",
    "    ## drops the significant number of columns that are all nulls\n",
    "    df = null_dropper(df)\n",
    "    \n",
    "    df.columns = [\"CRID\",\"Accused\",\"Accused_Gender\",\"Accused_Race_Code\",\"Date_of_Appt\",\"Current_Unit\",\"Current_Rank\",\n",
    "                  \"Star\",\"Complaint_Category\",\"Orig_Finding\",\"Orig_Recommended_Discipline\",\"Final_Finding\",\n",
    "                 \"Final_Recommended_Discipline\"]\n",
    "\n",
    "    ## Excel reads NA as null for Orig and Final Finding, this returns it to NA status when discipline is not null\n",
    "    df[\"Orig_Finding\"] = df['Orig_Finding'].astype(str)\n",
    "    df[\"Orig_Finding\"] =np.where((df[\"Orig_Finding\"]=='nan') & (~df[\"Orig_Recommended_Discipline\"].isnull()),\n",
    "                                 \"NA\",\n",
    "                                 df[\"Orig_Finding\"])\n",
    "\n",
    "    df[\"Final_Finding\"] = df['Final_Finding'].astype(str)\n",
    "    df[\"Final_Finding\"] = np.where((df[\"Final_Finding\"]=='nan') & (~df[\"Final_Recommended_Discipline\"].isnull()),\n",
    "                                 \"NA\",\n",
    "                                 df[\"Final_Finding\"])\n",
    "    \n",
    "    ## replace the actual nulls with blanks\n",
    "    df[\"Orig_Finding\"] = np.where((df[\"Orig_Finding\"]=='nan'),\n",
    "                                 \"\",\n",
    "                                 df[\"Orig_Finding\"])\n",
    "    df[\"Final_Finding\"] =np.where((df[\"Final_Finding\"]=='nan'),\n",
    "                                 \"\",\n",
    "                                 df[\"Final_Finding\"])\n",
    "\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_mar_2015_report2+\"foia_14-5509_-_report_2.csv\",index=False)\n",
    "final_df.to_excel(out_path_mar_2015_report2+\"foia_14-5509_-_report_2.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_mar_2015_report2+\"foia_14-5509_-_report_2_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foia 14-5509 - report 3 - police officer witness data xi.xls']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_mar_2015_report3 = in_path+'/march_2015/Report_3_-_Police_Witnesses/'\n",
    "out_path_mar_2015_report3 = out_path+'/march_2015/Report_3_-_Police_Witnesses/'\n",
    "\n",
    "files = os.listdir(in_path_mar_2015_report3)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_excel(in_path_mar_2015_report3 + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = col_list.pop()\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "    # +1 because of python indexing\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_mar_2015_report3 + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    ## Remove leading and trailing whitespace from columns \n",
    "    df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "    ## Filling Number Column\n",
    "    df['Unnamed: 4'].fillna(method='ffill', inplace=True)\n",
    "    df['Unnamed: 4'] = df['Unnamed: 4'].astype(int)\n",
    "\n",
    "    ## Drops end of record \n",
    "    df = df.dropna(subset=[\"Unnamed: 2\",\"Gender\",\"Star\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## drops the significant number of columns that are all nulls\n",
    "    df = null_dropper(df)\n",
    "\n",
    "    df.columns = [\"Officer_Witness\",\"CRID\",\"Officer_Witness_Gender\",\"Officer_Witness_Race\",\"Officer_Witness_Star\"]\n",
    "    df = df[[\"CRID\",\"Officer_Witness\",\"Officer_Witness_Gender\",\"Officer_Witness_Race\",\"Officer_Witness_Star\"]]\n",
    "\n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_mar_2015_report3+\"foia_14-5509_-_report_3.csv\",index=False)\n",
    "final_df.to_excel(out_path_mar_2015_report3+\"foia_14-5509_-_report_3.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_mar_2015_report3+\"foia_14-5509_-_report_3_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foia 14-5509 - report 4a - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4b - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4c - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4d - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4e - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4f - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4g - complaining witness data.xls',\n",
       " 'foia 14-5509 - report 4h - complaining witness data.xls']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_mar_2015_report4 = in_path+'/march_2015/Report_4_-_Complaining_Witnesses/'\n",
    "out_path_mar_2015_report4 = out_path+'/march_2015/Report_4_-_Complaining_Witnesses/'\n",
    "\n",
    "files = os.listdir(in_path_mar_2015_report4)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "metadata_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_excel(in_path_mar_2015_report4 + file,nrows=20)\n",
    "    ## Making Sure Every File contains date the file was created and the foia that created it\n",
    "    col_list = df.columns.tolist()\n",
    "    Report_Produced_Date = col_list.pop()\n",
    "    FOIA_Request = [x for x in col_list if 'FOIA' in x][0]\n",
    "\n",
    "    # +1 because of python indexing\n",
    "    skip = np.where(df.iloc[:,0]==\"Number:\")[0][0]+1\n",
    "    df = pd.read_excel(in_path_mar_2015_report4 + file, skiprows=skip)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    ## Remove leading and trailing whitespace from columns \n",
    "    df.columns = [col.strip() for col in df.columns.tolist()]\n",
    "\n",
    "    ## Filling Number Column\n",
    "    df['Unnamed: 2'].fillna(method='ffill', inplace=True)\n",
    "    df['Unnamed: 2'] = df['Unnamed: 2'].astype(int)\n",
    "\n",
    "    ## Drops end of record \n",
    "    df = df.dropna(subset=[\"Gender\",\"Race\"],how=\"all\",axis=0)\n",
    "\n",
    "    ## drops the significant number of columns that are all nulls\n",
    "    df = null_dropper(df)\n",
    "\n",
    "    df.columns = [\"CRID\",\"Witness_Gender\",\"Witness_Race\"]\n",
    "\n",
    "    ## drop end of record rows\n",
    "    df = df[df[\"Witness_Race\"]!=\"end of record\"]\n",
    "    \n",
    "    df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "    try:\n",
    "        df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "    except:\n",
    "        df[\"Report_Produced_Date\"]=''\n",
    "    final_df = final_df.append(df)\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    metadata_df = metadata_df.append(metadata_dataset(df,file))\n",
    "    metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_mar_2015_report4+\"foia_14-5509_-_report_4.csv\",index=False)\n",
    "final_df.to_excel(out_path_mar_2015_report4+\"foia_14-5509_-_report_4.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_mar_2015_report4+\"foia_14-5509_-_report_4_metadata.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Civis Model",
   "language": "python",
   "name": "civis-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
