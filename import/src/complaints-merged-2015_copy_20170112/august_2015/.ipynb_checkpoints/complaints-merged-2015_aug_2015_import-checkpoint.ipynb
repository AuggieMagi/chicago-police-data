{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that help with the magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can be used to remove columns that are all nulls so you don't have to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_dropper(df):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    info_values = [x[0] for x in info_values if x[1].startswith('0 non-null')]\n",
    "    df = df.drop(info_values,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates metadata as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metadata_dataset(df,file):\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    s = buf.getvalue()\n",
    "    info_values = [re.split(\"\\\\s\\\\s+\",x) for x in s.split(\"\\n\")]\n",
    "    info_values = [x for x in info_values if len(x)>1]\n",
    "    metadata_df = pd.DataFrame(info_values)\n",
    "    metadata_df[\"File\"] = file\n",
    "    metadata_df.columns = [\"Column_Name\",\"Column_Info\",\"Original_Dataset\"]\n",
    "    ## Column Info Split\n",
    "    metadata_df['Non_Null_Count'], metadata_df['Object_Type'] = metadata_df['Column_Info'].str.split(' ', 1).str\n",
    "    metadata_df[\"Object_Type\"] = metadata_df[\"Object_Type\"].str.replace(\"non-null \",\"\")\n",
    "    ## unique counts for each variable\n",
    "    uniques_df = df.apply(lambda x: len(x.unique())).reset_index()\n",
    "    uniques_df.columns = [\"Column_Name\",\"Unique_Count\"]\n",
    "    metadata_df[\"Unique_Count\"] = uniques_df[\"Unique_Count\"]\n",
    "    metadata_df = metadata_df[[\"Original_Dataset\",\"Column_Name\",\"Non_Null_Count\",\"Unique_Count\",\"Object_Type\"]]\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts single column named City_State_Zip into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def city_state_zip_splitter(df):\n",
    "    new_states_list=[]\n",
    "    for value in df[\"City_State_Zip\"]:\n",
    "        ## check if it contains a number (zipcode)\n",
    "        if hasNumbers(value):\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 3 values\n",
    "            while len(split_state)>3:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        else:\n",
    "            split_state = value.split(\" \")\n",
    "            ## join city names until we have 2 values\n",
    "            while len(split_state)>2:\n",
    "                split_state = [split_state[0]+' '+split_state[1]]+split_state[2:]\n",
    "        new_states_list.append(split_state)\n",
    "    city_state_zip =  pd.DataFrame(new_states_list)\n",
    "    city_state_zip.columns = [\"City\",\"State\",\"Zip\"]\n",
    "    return city_state_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishes General Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/thudson/Documents/Dat/chicago-police-data/import\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = path + '/input/complaints-merged-2015_copy_20170112'\n",
    "out_path =path + '/output/complaints-merged-2015_copy_20170112'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code = pd.read_csv(path+'/doc/Location_Code_Dictionary.csv')\n",
    "location_code.dropna(how='all', inplace=True)\n",
    "location_code['Location_Code']=location_code['Location_Code'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## August 2015 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FOIA 14-5509 - birth year of accused.xls',\n",
       " 'foia 14-5509 - complaining witness data.xls',\n",
       " 'foia 14-5509 - investigator data.xls']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path_aug_2015_report = in_path+'/august_2015/'\n",
    "out_path_aug_2015_report = out_path+'/august_2015/'\n",
    "\n",
    "files = os.listdir(in_path_aug_2015_report)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accused_Full_Name</th>\n",
       "      <th>Year_of_Birth</th>\n",
       "      <th>FOIA_Request_Number</th>\n",
       "      <th>Report_Produced_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARON, JEFFERY</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>FOIA 14-5509</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARON, KARINA</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>FOIA 14-5509</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABDELHADI, ABDALMAHD</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>FOIA 14-5509</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABDELMAJEID, AZIZ</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>FOIA 14-5509</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABRAHAM, NANCY</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>FOIA 14-5509</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accused_Full_Name  Year_of_Birth FOIA_Request_Number  \\\n",
       "0        AARON, JEFFERY         1971.0        FOIA 14-5509   \n",
       "1         AARON, KARINA         1980.0        FOIA 14-5509   \n",
       "2  ABDELHADI, ABDALMAHD         1978.0        FOIA 14-5509   \n",
       "3     ABDELMAJEID, AZIZ         1984.0        FOIA 14-5509   \n",
       "4        ABRAHAM, NANCY         1986.0        FOIA 14-5509   \n",
       "\n",
       "  Report_Produced_Date  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[0]\n",
    "df = pd.read_excel(in_path_aug_2015_report + file,nrows=20)\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = col_list.pop()\n",
    "FOIA_Request = file[:12].upper()\n",
    "# +1 because of python indexing, +1 because of header in first df\n",
    "skip = np.where(df.iloc[:,4]==\"Accused\")[0][0]+1+1\n",
    "df = pd.read_excel(in_path_aug_2015_report + file, skiprows=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "df.columns = [\"Accused_Full_Name\",\"Year_of_Birth\"]\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## DEPRECATED IN FAVOR OF ROSETTE API\n",
    "########################################\n",
    "\n",
    "\n",
    "## jr_splitter Created based on an exploration of First_Last_Name_List\n",
    "## test = pd.DataFrame(First_Last_Name_list)\n",
    "## test.shape[1]>2\n",
    "## test[~(test[2].isnull())]\n",
    "\n",
    "\n",
    "##First_Last_Name_list = df[\"Accused_Full_Name\"].str.split(\",\").tolist()\n",
    "\n",
    "def jr_splitter(row):\n",
    "    if len(row)>2:\n",
    "        return [row[0],row[2],\"JR\"]\n",
    "    elif \" JR\" in row[0]:\n",
    "        return [row[0][:row[0].find(\" JR\")],row[1],\"JR\"]\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "##df1 = pd.DataFrame([jr_splitter(row) for row in First_Last_Name_list])\n",
    "##df1.columns = [\"Accused_Last_Name\",\"Accused_First_Name\",\"Accused_Suffix\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "df[\"Report_Produced_Date\"]=Report_Produced_Date\n",
    "final_df = df\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_dataset(final_df,file)\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_birth_year_of_accused.csv\",index=False)\n",
    "final_df.to_excel(out_path_aug_2015_report+\"foia_14-5509_-_birth_year_of_accused.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_birth_year_of_accused_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = files[1]\n",
    "df = pd.read_excel(in_path_aug_2015_report + file,nrows=20)\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = col_list.pop()\n",
    "FOIA_Request = file[:12].upper()\n",
    "# +1 because of python indexing, +1 because of header in first df\n",
    "skip = np.where(df.iloc[:,2]==\"Number\")[0][0]+1+1\n",
    "df = pd.read_excel(in_path_aug_2015_report + file, skiprows=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "df['Number'].fillna(method='ffill', inplace=True)\n",
    "df['Number'] = df['Number'].astype(int)\n",
    "df = df.dropna(subset=[\"Gender\",\"Age\",\"Race Desc\"],how=\"all\",axis=0)\n",
    "df = null_dropper(df)\n",
    "df.columns = [\"CRID\",\"Witness_Gender\",\"Witness_Age\",\"Witness_Race\"]\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "final_df = df\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_dataset(final_df,file)\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_complaining_witness_data.csv\",index=False)\n",
    "final_df.to_excel(out_path_aug_2015_report+\"foia_14-5509_-_complaining_witness_data.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_complaining_witness_data_metadata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = files[2]\n",
    "df = pd.read_excel(in_path_aug_2015_report + file,nrows=20)\n",
    "## Additional Data\n",
    "col_list = df.columns.tolist()\n",
    "Report_Produced_Date = col_list.pop()\n",
    "FOIA_Request = file[:12].upper()\n",
    "# +1 because of python indexing, +1 because of header in first df\n",
    "skip = np.where(df.iloc[:,0]==\"Invst Last Name\")[0][0]+1+1\n",
    "df = pd.read_excel(in_path_aug_2015_report + file, skiprows=skip)\n",
    "df.dropna(how='all', inplace=True)\n",
    "## Drop all null columns\n",
    "df = null_dropper(df)\n",
    "df.columns = [\"Investigator_Last_Name\",\"Investigator_First_Name\",\"Current_Report\",\"Current_Rank\"]\n",
    "df[\"FOIA_Request_Number\"]=FOIA_Request\n",
    "try:\n",
    "    df[\"Report_Produced_Date\"]=Report_Produced_Date.date()\n",
    "except:\n",
    "    df[\"Report_Produced_Date\"]=''\n",
    "final_df = df\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "metadata_df = metadata_dataset(final_df,file)\n",
    "metadata_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_investigator_data.csv\",index=False)\n",
    "final_df.to_excel(out_path_aug_2015_report+\"foia_14-5509_-_investigator_data.xlsx\",index=False)\n",
    "\n",
    "metadata_df.to_csv(out_path_aug_2015_report+\"foia_14-5509_-_investigator_data_metadata.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Civis Model",
   "language": "python",
   "name": "civis-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
